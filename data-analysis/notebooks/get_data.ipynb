{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/bleopold/OneDrive/data-analysis/vendors/WikiSQL/data/dev.tables.jsonl'\n",
    "base_target_path = \"../data/01_raw/wiki-sql\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['table_id', 'column_name_original', 'column_name_clean', 'column_order']\n",
    "mapping_info_all_tables = pd.DataFrame(\n",
    "    columns = column_names\n",
    ")\n",
    "\n",
    "\n",
    "with open(path, 'r') as json_file:\n",
    "    tables_info_raw = list(json_file)\n",
    "    \n",
    "for table in tables_info_raw:\n",
    "    result = json.loads(table)\n",
    "    \n",
    "    table_id  = get_table_id(result)\n",
    "    original_column_names = get_table_columns(result)\n",
    "    \n",
    "    \n",
    "    mapping_info_one_table = pd.DataFrame(\n",
    "        columns = column_names\n",
    "    )\n",
    "\n",
    "    for idx, column_name_original in enumerate(original_column_names):\n",
    "        column_name_clean = slugify(column_name_original)\n",
    "\n",
    "\n",
    "        mapping_info_one_table.loc[idx, \"column_name_original\"] = column_name_original\n",
    "        mapping_info_one_table.loc[idx, \"column_name_clean\"] = column_name_clean\n",
    "        mapping_info_one_table.loc[idx, \"column_order\"] = idx\n",
    "        mapping_info_one_table[[\"table_id\"]] = table_id\n",
    "\n",
    "    mapping_info_all_tables = mapping_info_all_tables.append(mapping_info_one_table)\n",
    "\n",
    "    mapping_info_all_tables.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "mapping_info_all_tables.to_csv(\n",
    "        \"{}/mapping_column_names.csv\".format(base_target_path)\n",
    "        , sep='\\t'\n",
    "        , index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slugify(value):\n",
    "    \"\"\"\n",
    "    Normalize string name to be able to save to disk\n",
    "    \n",
    "    Based on: https://stackoverflow.com/questions/295135/turn-a-string-into-a-valid-filename\n",
    "    \"\"\"\n",
    "    value = re.sub('[^\\w\\s-]', '', value).strip().lower()\n",
    "    value = re.sub('[^\\w\\s-]', '', value).strip().lower()\n",
    "    value = value.replace(' ', '_')\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_columns(result):\n",
    "    table_columns = result['header']\n",
    "    return table_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_id(result):\n",
    "    table_id = result[\"id\"]\n",
    "    return table_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_table_as_df(result):\n",
    "    table_columns = result['header']\n",
    "    table_columns = [slugify(_) for _ in table_columns]\n",
    "    \n",
    "    table_rows = result['rows']\n",
    "\n",
    "    table_df = pd.DataFrame(columns = table_columns)\n",
    "    \n",
    "    for table_row in table_rows:\n",
    "        table_row_df = pd.DataFrame(columns = table_columns, data=[table_row])\n",
    "        table_df = table_df.append(table_row_df)\n",
    "    \n",
    "    table_df.reset_index(drop=True, inplace=True)\n",
    "    return table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_mapping_df = [\"table_id\", \"table_name\"]\n",
    "df_mapping = pd.DataFrame(columns=columns_mapping_df)\n",
    "\n",
    "\n",
    "with open(path, 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "\n",
    "for json_str in json_list[0:10]:\n",
    "    result = json.loads(json_str)\n",
    "    \n",
    "    # get table only if page_title exists\n",
    "    try:\n",
    "        page_title = result[\"page_title\"]\n",
    "        page_title = slugify(page_title)\n",
    "    except KeyError as e:\n",
    "        continue\n",
    "        \n",
    "        \n",
    "    table = get_data_for_table_as_df(result)\n",
    "    \n",
    "    # save table to disk\n",
    "    table_id = get_table_id(result)\n",
    "    table_file_path = '{}/{}.csv'.format(base_target_path, table_id)\n",
    "    table.to_csv(table_file_path, sep='\\t', index=False)\n",
    "    \n",
    "    # store mapping between table_id and table_name\n",
    "    df_mapping_ = pd.DataFrame(columns=columns_mapping_df, data=[[table_id, page_title]])\n",
    "    df_mapping = df_mapping.append(df_mapping_)\n",
    "    df_mapping.to_csv(\n",
    "        \"{}/mapping_table_id_page_title.csv\".format(base_target_path)\n",
    "        , sep='\\t'\n",
    "        , index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
